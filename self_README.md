This repository will contain my work for several different RL environments.

Here is the link to the gymnasium API, which you will use to get better at RL for now:
[Gymnasium](https://gymnasium.farama.org)

Here is a link to a repository that contains several really cool RL environments
you may want to try making agents for later:
[Cool RL Environments](https://github.com/clvrai/awesome-rl-envs?tab=readme-ov-file)

To activate the conda environment for gymnasium, run this command:
conda activate gymnasium

Possible list of RL algorithms to implement in order:
1. Dynamic Programming (DP):
Start with DP concepts like value iteration and policy iteration. These provide a foundational understanding of how to compute optimal policies in a Markov Decision Process (MDP). 

2. Q-learning:
Implement Q-learning, a model-free RL algorithm that directly estimates the Q-values for actions in different states. 

3. Deep Q-Network (DQN):
Explore DQN, which uses deep neural networks to approximate Q-values, allowing for learning in complex environments. 

4. Policy Gradient Methods:
Move on to policy gradient methods like REINFORCE, which directly optimize the policy parameters. 

5. Actor-Critic Methods:
Consider actor-critic methods like A2C, A3C, PPO, and TRPO, which combine value-based and policy-based approaches. 

6. DDPG, SAC, and TD3:
Explore these continuous action space algorithms, which are popular for tasks involving continuous control. 

7. Model-Based RL:
Consider model-based algorithms like World Models or Imagination-Augmented Agents for environments where a model of the environment can be learned. 

8. Other Advanced Techniques:
Explore more specialized techniques like hierarchical reinforcement learning, meta-learning, and transfer learning as needed for specific applications. 