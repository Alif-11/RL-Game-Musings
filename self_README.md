This repository will contain my work for several different RL environments.

Here is the link to the gymnasium API, which you will use to get better at RL for now:
[Gymnasium](https://gymnasium.farama.org)

Here is a link to a repository that contains several really cool RL environments
you may want to try making agents for later:
[Cool RL Environments](https://github.com/clvrai/awesome-rl-envs?tab=readme-ov-file)

To activate the conda environment for this repository's blackjack project, run this command:
conda activate gymnasium


[Environment API Docs](https://gymnasium.farama.org/api/env/)

[Action Space and Observation Space API Docs](https://gymnasium.farama.org/api/spaces/)

[Blackjack Gymnasium Page](https://gymnasium.farama.org/environments/toy_text/blackjack/)

[Reference website to making your own Blackjack Q-Learning Agent](https://gymnasium.farama.org/introduction/train_agent/)

[Guide you're following to learn Q-Learning Algorithm](https://rezaborhani.github.io/mlr/blog_posts/Reinforcement_Learning/Q_learning.html)


Possible list of RL algorithms to implement in order:
1. Dynamic Programming (DP):
Start with DP concepts like value iteration and policy iteration. These provide a foundational understanding of how to compute optimal policies in a Markov Decision Process (MDP). 

1. Q-learning:
Implement Q-learning, a model-free RL algorithm that directly estimates the Q-values for actions in different states. 

1. Deep Q-Network (DQN):
Explore DQN, which uses deep neural networks to approximate Q-values, allowing for learning in complex environments. 

1. Policy Gradient Methods:
Move on to policy gradient methods like REINFORCE, which directly optimize the policy parameters. 

1. Actor-Critic Methods:
Consider actor-critic methods like A2C, A3C, PPO, and TRPO, which combine value-based and policy-based approaches. 

1. DDPG, SAC, and TD3:
Explore these continuous action space algorithms, which are popular for tasks involving continuous control. 

1. Model-Based RL:
Consider model-based algorithms like World Models or Imagination-Augmented Agents for environments where a model of the environment can be learned. 

1. Other Advanced Techniques:
Explore more specialized techniques like hierarchical reinforcement learning, meta-learning, and transfer learning as needed for specific applications. 